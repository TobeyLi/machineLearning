{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>low_volume_percent</th>\n",
       "      <th>middle_volume_percent</th>\n",
       "      <th>take_amount_in_later_12_month_highest</th>\n",
       "      <th>trans_amount_increase_rate_lately</th>\n",
       "      <th>trans_activity_month</th>\n",
       "      <th>trans_activity_day</th>\n",
       "      <th>transd_mcc</th>\n",
       "      <th>trans_days_interval_filter</th>\n",
       "      <th>trans_days_interval</th>\n",
       "      <th>regional_mobility</th>\n",
       "      <th>...</th>\n",
       "      <th>loans_max_limit</th>\n",
       "      <th>loans_avg_limit</th>\n",
       "      <th>consfin_credit_limit</th>\n",
       "      <th>consfin_credibility</th>\n",
       "      <th>consfin_org_count_current</th>\n",
       "      <th>consfin_product_count</th>\n",
       "      <th>consfin_max_limit</th>\n",
       "      <th>consfin_avg_limit</th>\n",
       "      <th>latest_query_day</th>\n",
       "      <th>loans_latest_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.89</td>\n",
       "      <td>900</td>\n",
       "      <td>1.19</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.330</td>\n",
       "      <td>16.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>1433.0</td>\n",
       "      <td>7400.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16800.0</td>\n",
       "      <td>6620.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0</td>\n",
       "      <td>1.45</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.085</td>\n",
       "      <td>8.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>4400.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4800.0</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.661</td>\n",
       "      <td>10.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7400.0</td>\n",
       "      <td>2355.0</td>\n",
       "      <td>11300.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>22200.0</td>\n",
       "      <td>10120.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.96</td>\n",
       "      <td>100</td>\n",
       "      <td>1.16</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.261</td>\n",
       "      <td>19.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>2100.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>126.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.90</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.71</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.558</td>\n",
       "      <td>21.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8100.0</td>\n",
       "      <td>2138.0</td>\n",
       "      <td>12400.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>22200.0</td>\n",
       "      <td>9840.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   low_volume_percent  middle_volume_percent  \\\n",
       "0                0.01                   0.89   \n",
       "1                0.01                   0.99   \n",
       "2                0.00                   0.08   \n",
       "3                0.04                   0.96   \n",
       "4                0.01                   0.90   \n",
       "\n",
       "   take_amount_in_later_12_month_highest  trans_amount_increase_rate_lately  \\\n",
       "0                                    900                               1.19   \n",
       "1                                      0                               1.45   \n",
       "2                                      0                               0.11   \n",
       "3                                    100                               1.16   \n",
       "4                                   2000                               0.71   \n",
       "\n",
       "   trans_activity_month  trans_activity_day  transd_mcc  \\\n",
       "0                  0.91               0.330        16.0   \n",
       "1                  0.41               0.085         8.0   \n",
       "2                  0.97               0.661        10.0   \n",
       "3                  0.90               0.261        19.0   \n",
       "4                  1.00               0.558        21.0   \n",
       "\n",
       "   trans_days_interval_filter  trans_days_interval  regional_mobility  ...  \\\n",
       "0                        24.0                 23.0                3.0  ...   \n",
       "1                        59.0                 58.0                2.0  ...   \n",
       "2                        44.0                  7.0                2.0  ...   \n",
       "3                        25.0                 25.0                3.0  ...   \n",
       "4                        17.0                 15.0                5.0  ...   \n",
       "\n",
       "   loans_max_limit  loans_avg_limit  consfin_credit_limit  \\\n",
       "0           2400.0           1433.0                7400.0   \n",
       "1           2500.0           2500.0                4400.0   \n",
       "2           7400.0           2355.0               11300.0   \n",
       "3           3300.0           2100.0                2400.0   \n",
       "4           8100.0           2138.0               12400.0   \n",
       "\n",
       "   consfin_credibility  consfin_org_count_current  consfin_product_count  \\\n",
       "0                 81.0                       10.0                   11.0   \n",
       "1                 79.0                        2.0                    3.0   \n",
       "2                 77.0                       10.0                   11.0   \n",
       "3                 78.0                        1.0                    1.0   \n",
       "4                 80.0                       10.0                   12.0   \n",
       "\n",
       "   consfin_max_limit  consfin_avg_limit  latest_query_day  loans_latest_day  \n",
       "0            16800.0             6620.0               8.0              38.0  \n",
       "1             4800.0             3300.0              20.0              39.0  \n",
       "2            22200.0            10120.0               3.0               3.0  \n",
       "3             2400.0             2400.0               7.0             126.0  \n",
       "4            22200.0             9840.0               4.0              27.0  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 导入相关的数据\n",
    "train_data=pd.read_csv('../data/train_data.csv',encoding='utf-8')\n",
    "test_data=pd.read_csv('../data/test_data.csv',encoding='utf-8')\n",
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 得到训练数据与测试数据\n",
    "train_y=train_data['status']\n",
    "train_X=train_data.drop(['status'],axis=1)\n",
    "\n",
    "test_y=test_data['status']\n",
    "test_X=test_data.drop(['status'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用LR来计算准确率\n",
    "---\n",
    "导入LR模型，然后使用LR模型来计算正确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "J:\\python\\env\\nlp\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr=LogisticRegression()\n",
    "lr.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7581009796533534"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算决定系数R^2\n",
    "lr.score(test_X,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict=lr.predict(test_X)\n",
    "test_y=test_y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算准确率\n",
    "def cal_precision(predict,true_label):\n",
    "    count=0\n",
    "    for label1,label2 in zip(predict,true_label):\n",
    "        if label1==label2:\n",
    "            count+=1\n",
    "    return count/len(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7581009796533534"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_precision(predict,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1006,  320],\n",
       "       [   1,    0]], dtype=int64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 尝试画出混淆矩阵\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "cm=confusion_matrix(predict,test_y)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=[1,0]\n",
    "\n",
    "cm_normalized = cm.astype('float')/cm.sum(axis=1)[:, np.newaxis]\n",
    "def plot_confusion_matrix(cm, title='Confusion Matrix', cmap = plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    xlocations = np.array(range(len(labels)))\n",
    "    plt.xticks(xlocations, labels, rotation=90)\n",
    "    plt.yticks(xlocations, labels)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "plot_confusion_matrix(cm_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用SVM来拟合数据\n",
    "---\n",
    "借助于sklearn中实现的SVM包来求取准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "J:\\python\\env\\nlp\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm=SVC()\n",
    "svm.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.758854559155991"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_svm=svm.predict(test_X)\n",
    "cal_precision(predict_svm,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用随机森林来拟合数据\n",
    "----\n",
    "说那个sklearn写好的包RandomForest去拟合数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "J:\\python\\env\\nlp\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest=RandomForestClassifier()\n",
    "random_forest.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7709118311981914"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_rf=random_forest.predict(test_X)\n",
    "cal_precision(predict_rf,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用XGboost来拟合数据\n",
    "----\n",
    "xgboost自己之前是学习过的，但是没有明确各个参数逇意义，现在借此机会，明确xgboost中各个参数的意义\n",
    "Reference:刘建平老师关于xgboost的讲解：https://www.cnblogs.com/pinard/p/11114748.html\n",
    "对于XGBoost的框架参数，最重要的是3个参数: booster，n_estimators和objectve。\n",
    "\n",
    "1) booster决定了XGBoost使用的弱学习器类型，可以是默认的gbtree, 也就是CART决策树，还可以是线性弱学习器gblinear以及DART。一般来说，我们使用gbtree就可以了，不需要调参。  \n",
    "2) n_estimators则是非常重要的要调的参数，它关系到我们XGBoost模型的复杂度，因为它代表了我们决策树弱学习器的个数。这个参数对应sklearn GBDT的n_estimators。n_estimators太小，容易欠拟合，n_estimators太大，模型会过于复杂，一般需要调参选择一个适中的数值。  \n",
    "3) objective代表了我们要解决的问题是分类还是回归，或其他问题，以及对应的损失函数。具体可以取的值很多，一般我们只关心在分类和回归的时候使用的参数。在回归问题objective一般使用reg:squarederror ，即MSE均方误差。二分类问题一般使用binary:logistic, 多分类问题一般使用multi:softmax。 \n",
    "  \n",
    "**XGBoost 弱学习器参数**  \n",
    " max_depth: 控制树结构的深度，数据少或者特征少的时候可以不管这个值。如果模型样本量多，特征也多的情况下，需要限制这个最大深度，具体的取值一般要网格搜索调参。  \n",
    " min_child_weight: 最小的子节点权重阈值，如果某个树节点的权重小于这个阈值，则不会再分裂子树，即这个树节点就是叶子节点。  \n",
    " gamma: XGBoost的决策树分裂所带来的损失减小阈值。  \n",
    " subsample: 子采样参数，这个也是不放回抽样  \n",
    " colsample_bytree/colsample_bylevel/colsample_bynode: 这三个参数都是用于特征采样的，默认都是不做采样，即使用所有的特征建立决策树。  colsample_bytree控制整棵树的特征采样比例，colsample_bylevel控制某一层的特征采样比例，而colsample_bynode控制某一个树节点的特征采样比例。  \n",
    " reg_alpha/reg_lambda: 这2个是XGBoost的正则化参数。reg_alpha是L1正则化系数，reg_lambda是L1正则化系数；  \n",
    " learning_rate控制每个弱学习器的权重缩减系数；  \n",
    " n_jobs控制算法的并发线程数；  \n",
    " scale_pos_weight用于类别不平衡的时候，负例和正例的比例；\n",
    " importance_type则可以查询各个特征的重要性程度。可以选择“gain”, “weight”, “cover”, “total_gain” 或者 “total_cover”；\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置xgboost参数\n",
    "params={\n",
    "        'booster':'gbtree',\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'auc',\n",
    "        'gamma':0,\n",
    "        'max_depth':3,\n",
    "        'subsample':0.7,\n",
    "        'colsample_bytree':0.7,\n",
    "        'min_child_weight':0, \n",
    "        'eta': 0.04,\n",
    "        'seed':2018\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备数据集\n",
    "dtrain = xgb.DMatrix(train_X,train_y)\n",
    "dtest = xgb.DMatrix(test_X,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "raw_model = xgb.train(params, dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train_raw = raw_model.predict(dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8032945736434108\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "for i in range(len(pred_train_raw)):\n",
    "    if pred_train_raw[i] > 0.5:\n",
    "         pred_train_raw[i]=1\n",
    "    else:\n",
    "        pred_train_raw[i]=0               \n",
    "print (accuracy_score(dtrain.get_label(), pred_train_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
