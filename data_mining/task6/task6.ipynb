{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "使用Stacking方法来完成模型融合\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读入数据\n",
    "train=pd.read_csv('../data/train_data.csv')\n",
    "test=pd.read_csv('../data/test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练集与测试集的导入\n",
    "train_y=train['status']\n",
    "train_X=train.drop(['status'],axis=1)\n",
    "\n",
    "test_y=test['status']\n",
    "test_X=test.drop(['status'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据归一化操作\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "train_X=minmax_scale(train_X)\n",
    "test_X=minmax_scale(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用模型来拟合数据并且查看准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier,RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'C': 10} with a score of 0.80\n"
     ]
    }
   ],
   "source": [
    "# 使用逻辑回归运行五折交叉验证，网格搜索来获取最优参数\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# C为正则化系数λ的倒数，必须为正数，默认为1，值越小，代表正则化越强。一般来说，只需要调节这个参数\n",
    "grid_lr = GridSearchCV(LogisticRegression(), param_grid={\"C\":[0.01,0.05,0.1,0.2,0.5, 1, 10]}, cv=5)\n",
    "grid_lr.fit(train_X,train_y)\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (grid_lr.best_params_, grid_lr.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'C': 10, 'gamma': 0.1} with a score of 0.79\n"
     ]
    }
   ],
   "source": [
    "# 使用SVM运行五折交叉验证，网格搜索来获取最优参数\n",
    "\n",
    "# 惩罚系数C,核函数参数gamma,可以调节这两个餐素\n",
    "grid_svm=GridSearchCV(SVC(probability=True),param_grid={\"C\":[0.1,0.5, 1, 10,20], \"gamma\": [1, 0.5,0.1, 0.01]})\n",
    "grid_svm.fit(train_X,train_y)\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (grid_svm.best_params_, grid_svm.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'max_depth': 4} with a score of 0.76\n"
     ]
    }
   ],
   "source": [
    "# 使用决策树运行五折交叉验证，网格搜索来获取最优参数\n",
    "\n",
    "# 决策树的模型一般这是需要调节最大深度即可\n",
    "grid_dt=GridSearchCV(DecisionTreeClassifier(),param_grid={\"max_depth\":[i for i in range(1,10)]},cv=5)\n",
    "grid_dt.fit(train_X,train_y)\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (grid_dt.best_params_, grid_dt.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'learning_rate': 0.05, 'n_estimators': 80}, 0.8007820916826951)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GBDT进行调参，这个过程可以分为如下进行\n",
    "\n",
    "# 1。先对步长和迭代次数进行调参\n",
    "param_test1 = {'n_estimators':range(20,81,10),'learning_rate':[0.05,0.1,0.2,0.5]}\n",
    "grid_gbdt = GridSearchCV(estimator = GradientBoostingClassifier(min_samples_split=300,\n",
    "                                  min_samples_leaf=20,max_depth=8,max_features='sqrt', subsample=0.8,random_state=10), \n",
    "                       param_grid = param_test1, scoring='roc_auc',iid=False,cv=5)\n",
    "grid_gbdt.fit(train_X,train_y)\n",
    "grid_gbdt.best_params_, grid_gbdt.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'max_depth': 5, 'min_samples_split': 300}, 0.8028316783445085)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.对其弱分类器决策树进行调参\n",
    "param_test2 = {'max_depth':range(3,14,2), 'min_samples_split':range(100,801,200)}\n",
    "gsearch2 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.05, n_estimators=80, min_samples_leaf=20, \n",
    "      max_features='sqrt', subsample=0.8, random_state=10), \n",
    "   param_grid = param_test2, scoring='roc_auc',iid=False, cv=5)\n",
    "gsearch2.fit(train_X,train_y)\n",
    "gsearch2.best_params_, gsearch2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'min_samples_leaf': 70, 'min_samples_split': 800}, 0.7992744969014101)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.对内部节点再划分所需最小样本数min_samples_split和叶子节点最少样本数min_samples_leaf一起调参。\n",
    "param_test3 = {'min_samples_split':range(800,1900,200), 'min_samples_leaf':range(60,101,10)}\n",
    "gsearch3 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.05, n_estimators=80,max_depth=13,\n",
    "                                     max_features='sqrt', subsample=0.8, random_state=10), \n",
    "                       param_grid = param_test3, scoring='roc_auc',iid=False, cv=5)\n",
    "gsearch3.fit(train_X,train_y)\n",
    "gsearch3.best_params_, gsearch3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'n_estimators': 70}, 0.7935017280083538)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对于RF，也可以按照上面的流程进行调参\n",
    "# 1。先对步长和迭代次数进行调参\n",
    "param_test1 = {'n_estimators':range(10,71,10)}\n",
    "gsearch1 = GridSearchCV(estimator = RandomForestClassifier(min_samples_split=100,\n",
    "                                  min_samples_leaf=20,max_depth=8,max_features='sqrt' ,random_state=10), \n",
    "                       param_grid = param_test1, scoring='roc_auc',cv=5)\n",
    "gsearch1.fit(train_X,train_y)\n",
    "gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'max_depth': 5, 'min_samples_split': 70}, 0.7947707409289428)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.对其弱分类器决策树进行调参\n",
    "param_test2 = {'max_depth':range(3,14,2), 'min_samples_split':range(50,201,20)}\n",
    "gsearch2 = GridSearchCV(estimator = RandomForestClassifier(n_estimators= 60, \n",
    "                                  min_samples_leaf=20,max_features='sqrt' ,oob_score=True, random_state=10),\n",
    "   param_grid = param_test2, scoring='roc_auc',iid=False, cv=5)\n",
    "gsearch2.fit(train_X,train_y)\n",
    "gsearch2.best_params_, gsearch2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'min_samples_leaf': 20, 'min_samples_split': 80}, 0.7966553035766241)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.对内部节点再划分所需最小样本数min_samples_split和叶子节点最少样本数min_samples_leaf一起调参。\n",
    "param_test3 = {'min_samples_split':range(80,150,20), 'min_samples_leaf':range(10,60,10)}\n",
    "gsearch3 = GridSearchCV(estimator = RandomForestClassifier(n_estimators= 70, max_depth=13,\n",
    "                                  max_features='sqrt' ,oob_score=True, random_state=10),\n",
    "   param_grid = param_test3, scoring='roc_auc',iid=False, cv=5)\n",
    "gsearch3.fit(train_X,train_y)\n",
    "gsearch3.best_params_, gsearch3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'leaf_size': 10, 'n_neighbors': 15}, 0.7558139534883721)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# KNN,主要是k值的选择，以及停止建子树的叶子节点阈值leaf_size的参数的选择\n",
    "params={'n_neighbors':[i for i in range(1,20,2)],'leaf_size':[i for i in range(10,100,10)]}\n",
    "gsearch4 = GridSearchCV(estimator = KNeighborsClassifier(),param_grid = params,cv=5)\n",
    "gsearch4.fit(train_X,train_y)\n",
    "gsearch4.best_params_, gsearch4.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=10, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=19, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用上面使用的最优的参数进行建模\n",
    "#  LogisticRegression\n",
    "lr=LogisticRegression(C=1)\n",
    "lr.fit(train_X,train_y)\n",
    "\n",
    "# SVM\n",
    "svm=SVC(C=10,gamma=0.1,probability=True)\n",
    "svm.fit(train_X,train_y)\n",
    "\n",
    "# DecisionTree\n",
    "dt=DecisionTreeClassifier(max_depth=4)\n",
    "dt.fit(train_X,train_y)\n",
    "\n",
    "# RF\n",
    "rf=RandomForestClassifier(n_estimators=60,max_depth=13,min_samples_split=80,min_samples_leaf=10)\n",
    "rf.fit(train_X,train_y)\n",
    "\n",
    "# GBDT\n",
    "gbdt=GradientBoostingClassifier(learning_rate=0.01,n_estimators=80,max_depth=13,min_samples_split=300,min_samples_leaf=60)\n",
    "gbdt.fit(train_X,train_y)\n",
    "\n",
    "# KNN\n",
    "knn=KNeighborsClassifier(n_neighbors=19,leaf_size=10)\n",
    "knn.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 当存在多个模型的时候，我们可以一起输出准确率，尝试使用列表的形式\n",
    "names=[\"LR\",\"SVM\",\"DecisionTree\",\"RF\",\"KNN\",\"GBDT\"]\n",
    "models=[lr,svm,dt,rf,knn,gbdt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR 训练集： accuracy:1.0,precision:0.744, recall:0.34, f1:0.467, auc:0.81\n",
      "LR 测试集： accuracy:1.0,precision:0.669, recall:0.291, f1:0.405, auc:0.772\n",
      "\n",
      "\n",
      "SVM 训练集： accuracy:1.0,precision:0.838, recall:0.346, f1:0.489, auc:0.864\n",
      "SVM 测试集： accuracy:1.0,precision:0.632, recall:0.284, f1:0.392, auc:0.756\n",
      "\n",
      "\n",
      "DecisionTree 训练集： accuracy:1.0,precision:0.749, recall:0.334, f1:0.462, auc:0.785\n",
      "DecisionTree 测试集： accuracy:1.0,precision:0.577, recall:0.294, f1:0.389, auc:0.686\n",
      "\n",
      "\n",
      "RF 训练集： accuracy:1.0,precision:0.865, recall:0.339, f1:0.487, auc:0.894\n",
      "RF 测试集： accuracy:1.0,precision:0.695, recall:0.334, f1:0.451, auc:0.769\n",
      "\n",
      "\n",
      "KNN 训练集： accuracy:1.0,precision:0.721, recall:0.166, f1:0.27, auc:0.77\n",
      "KNN 测试集： accuracy:1.0,precision:0.621, recall:0.169, f1:0.265, auc:0.693\n",
      "\n",
      "\n",
      "GBDT 训练集： accuracy:1.0,precision:0.895, recall:0.129, f1:0.225, auc:0.861\n",
      "GBDT 测试集： accuracy:1.0,precision:0.829, recall:0.0906, f1:0.163, auc:0.747\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>AUC-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LR</th>\n",
       "      <th>train</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.743802</td>\n",
       "      <td>0.340479</td>\n",
       "      <td>0.467128</td>\n",
       "      <td>0.809639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.669065</td>\n",
       "      <td>0.290625</td>\n",
       "      <td>0.405229</td>\n",
       "      <td>0.772362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SVM</th>\n",
       "      <th>train</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.837920</td>\n",
       "      <td>0.345523</td>\n",
       "      <td>0.489286</td>\n",
       "      <td>0.863781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.631944</td>\n",
       "      <td>0.284375</td>\n",
       "      <td>0.392241</td>\n",
       "      <td>0.756191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">DecisionTree</th>\n",
       "      <th>train</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.748588</td>\n",
       "      <td>0.334174</td>\n",
       "      <td>0.462075</td>\n",
       "      <td>0.785285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.293750</td>\n",
       "      <td>0.389234</td>\n",
       "      <td>0.686473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">RF</th>\n",
       "      <th>train</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.864952</td>\n",
       "      <td>0.339218</td>\n",
       "      <td>0.487319</td>\n",
       "      <td>0.893763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.694805</td>\n",
       "      <td>0.334375</td>\n",
       "      <td>0.451477</td>\n",
       "      <td>0.769200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">KNN</th>\n",
       "      <th>train</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.721311</td>\n",
       "      <td>0.166456</td>\n",
       "      <td>0.270492</td>\n",
       "      <td>0.770401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.168750</td>\n",
       "      <td>0.265356</td>\n",
       "      <td>0.692568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">GBDT</th>\n",
       "      <th>train</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.128625</td>\n",
       "      <td>0.224917</td>\n",
       "      <td>0.860916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.090625</td>\n",
       "      <td>0.163380</td>\n",
       "      <td>0.747027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Accuracy  Precision    Recall  F1-Score  AUC-Score\n",
       "LR           train       1.0   0.743802  0.340479  0.467128   0.809639\n",
       "             test        1.0   0.669065  0.290625  0.405229   0.772362\n",
       "SVM          train       1.0   0.837920  0.345523  0.489286   0.863781\n",
       "             test        1.0   0.631944  0.284375  0.392241   0.756191\n",
       "DecisionTree train       1.0   0.748588  0.334174  0.462075   0.785285\n",
       "             test        1.0   0.576687  0.293750  0.389234   0.686473\n",
       "RF           train       1.0   0.864952  0.339218  0.487319   0.893763\n",
       "             test        1.0   0.694805  0.334375  0.451477   0.769200\n",
       "KNN          train       1.0   0.721311  0.166456  0.270492   0.770401\n",
       "             test        1.0   0.620690  0.168750  0.265356   0.692568\n",
       "GBDT         train       1.0   0.894737  0.128625  0.224917   0.860916\n",
       "             test        1.0   0.828571  0.090625  0.163380   0.747027"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "df_list=[]\n",
    "for name,model in zip(names,models):\n",
    "    y_train_pred=model.predict(train_X)\n",
    "    y_test_pred=model.predict(test_X)\n",
    "    \n",
    "    # accuracy\n",
    "    train_accuracy=model.score(train_X,y_train_pred)\n",
    "    test_accuracy=model.score(test_X,y_test_pred)\n",
    "    \n",
    "    # precision\n",
    "    train_precision=precision_score(train_y,y_train_pred)\n",
    "    test_precision=precision_score(test_y,y_test_pred)\n",
    "    \n",
    "    # recall\n",
    "    train_recall=recall_score(train_y,y_train_pred)\n",
    "    test_recall=recall_score(test_y,y_test_pred)\n",
    "    \n",
    "    # f1\n",
    "    train_f1=f1_score(train_y,y_train_pred)\n",
    "    test_f1=f1_score(test_y,y_test_pred)\n",
    "    \n",
    "    # auc\n",
    "    y_train_pred=model.predict_proba(train_X)[:,1]\n",
    "    y_test_pred=model.predict_proba(test_X)[:,1]\n",
    "    \n",
    "    train_auc=roc_auc_score(train_y,y_train_pred)\n",
    "    test_auc=roc_auc_score(test_y,y_test_pred)\n",
    "    \n",
    "    print('{} 训练集： accuracy:{:.3},precision:{:.3}, recall:{:.3}, f1:{:.3}, auc:{:.3}'.format(name,train_accuracy,train_precision,train_recall,train_f1,train_auc))\n",
    "    print('{} 测试集： accuracy:{:.3},precision:{:.3}, recall:{:.3}, f1:{:.3}, auc:{:.3}'.format(name,test_accuracy,test_precision,test_recall,test_f1,test_auc))\n",
    "    print('\\n')\n",
    "    df = pd.DataFrame(np.array([train_accuracy,train_precision,train_recall,train_f1,train_auc,test_accuracy,test_precision,test_recall,test_f1,test_auc]).reshape(2,-1),\n",
    "                  index = ['train','test'],\n",
    "                  columns = ['Accuracy','Precision','Recall','F1-Score','AUC-Score'])\n",
    "    df_list.append(df)\n",
    "pd.concat(df_list,axis=0,keys=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入相关的stacking的工具，然后将比较好的模型来做一个融合\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "# stacking融合算法的目标是在每个子模块1、子模块2的设计选择过程中要尽可能的保证：\n",
    "# high biase\n",
    "# low var\n",
    "# 在子模块meta_classifier的时候，要保证：\n",
    "\n",
    "# low biase\n",
    "# high var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sclf = StackingClassifier(classifiers=[lr, gbdt,rf,svm], meta_classifier=svm)\n",
    "sclf1 = StackingClassifier(classifiers=[gbdt,svm,knn], meta_classifier=knn)\n",
    "sclf2 = StackingClassifier(classifiers=[gbdt,svm,dt], meta_classifier=lr)\n",
    "sclf3 = StackingClassifier(classifiers=[svm,dt], meta_classifier=rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_names=['sclf','sclf1','sclf2','sclf3']\n",
    "stack_models=[sclf,sclf1,sclf2,sclf3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sclf 训练集： accuracy:1.0,precision:0.836, recall:0.406, f1:0.547, auc:0.695\n",
      "sclf 测试集： accuracy:1.0,precision:0.611, recall:0.344, f1:0.44, auc:0.642\n",
      "\n",
      "\n",
      "sclf1 训练集： accuracy:1.0,precision:0.838, recall:0.346, f1:0.489, auc:0.667\n",
      "sclf1 测试集： accuracy:1.0,precision:0.632, recall:0.284, f1:0.392, auc:0.629\n",
      "\n",
      "\n",
      "sclf2 训练集： accuracy:1.0,precision:0.761, recall:0.456, f1:0.571, auc:0.707\n",
      "sclf2 测试集： accuracy:1.0,precision:0.547, recall:0.384, f1:0.451, auc:0.648\n",
      "\n",
      "\n",
      "sclf3 训练集： accuracy:1.0,precision:0.761, recall:0.456, f1:0.571, auc:0.707\n",
      "sclf3 测试集： accuracy:1.0,precision:0.547, recall:0.384, f1:0.451, auc:0.648\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>AUC-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LR</th>\n",
       "      <th>train</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.836364</td>\n",
       "      <td>0.406053</td>\n",
       "      <td>0.546689</td>\n",
       "      <td>0.694525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.343750</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.641516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SVM</th>\n",
       "      <th>train</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.837920</td>\n",
       "      <td>0.345523</td>\n",
       "      <td>0.489286</td>\n",
       "      <td>0.667489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.631944</td>\n",
       "      <td>0.284375</td>\n",
       "      <td>0.392241</td>\n",
       "      <td>0.629193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">DecisionTree</th>\n",
       "      <th>train</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.760504</td>\n",
       "      <td>0.456494</td>\n",
       "      <td>0.570528</td>\n",
       "      <td>0.706954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.546667</td>\n",
       "      <td>0.384375</td>\n",
       "      <td>0.451376</td>\n",
       "      <td>0.647691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">RF</th>\n",
       "      <th>train</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.760504</td>\n",
       "      <td>0.456494</td>\n",
       "      <td>0.570528</td>\n",
       "      <td>0.707264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.546667</td>\n",
       "      <td>0.384375</td>\n",
       "      <td>0.451376</td>\n",
       "      <td>0.648104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Accuracy  Precision    Recall  F1-Score  AUC-Score\n",
       "LR           train       1.0   0.836364  0.406053  0.546689   0.694525\n",
       "             test        1.0   0.611111  0.343750  0.440000   0.641516\n",
       "SVM          train       1.0   0.837920  0.345523  0.489286   0.667489\n",
       "             test        1.0   0.631944  0.284375  0.392241   0.629193\n",
       "DecisionTree train       1.0   0.760504  0.456494  0.570528   0.706954\n",
       "             test        1.0   0.546667  0.384375  0.451376   0.647691\n",
       "RF           train       1.0   0.760504  0.456494  0.570528   0.707264\n",
       "             test        1.0   0.546667  0.384375  0.451376   0.648104"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_df_list=[]\n",
    "for name,model in zip(stack_names,stack_models):\n",
    "    model.fit(train_X, train_y)  \n",
    "    y_train_pred=model.predict(train_X)\n",
    "    y_test_pred=model.predict(test_X)\n",
    "    \n",
    "    # accuracy\n",
    "    train_accuracy=model.score(train_X,y_train_pred)\n",
    "    test_accuracy=model.score(test_X,y_test_pred)\n",
    "    \n",
    "    # precision\n",
    "    train_precision=precision_score(train_y,y_train_pred)\n",
    "    test_precision=precision_score(test_y,y_test_pred)\n",
    "    \n",
    "    # recall\n",
    "    train_recall=recall_score(train_y,y_train_pred)\n",
    "    test_recall=recall_score(test_y,y_test_pred)\n",
    "    \n",
    "    # f1\n",
    "    train_f1=f1_score(train_y,y_train_pred)\n",
    "    test_f1=f1_score(test_y,y_test_pred)\n",
    "    \n",
    "    # auc\n",
    "    y_train_pred=model.predict_proba(train_X)[:,1]\n",
    "    y_test_pred=model.predict_proba(test_X)[:,1]\n",
    "    \n",
    "    train_auc=roc_auc_score(train_y,y_train_pred)\n",
    "    test_auc=roc_auc_score(test_y,y_test_pred)\n",
    "    \n",
    "    print('{} 训练集： accuracy:{:.3},precision:{:.3}, recall:{:.3}, f1:{:.3}, auc:{:.3}'.format(name,train_accuracy,train_precision,train_recall,train_f1,train_auc))\n",
    "    print('{} 测试集： accuracy:{:.3},precision:{:.3}, recall:{:.3}, f1:{:.3}, auc:{:.3}'.format(name,test_accuracy,test_precision,test_recall,test_f1,test_auc))\n",
    "    print('\\n')\n",
    "    df = pd.DataFrame(np.array([train_accuracy,train_precision,train_recall,train_f1,train_auc,test_accuracy,test_precision,test_recall,test_f1,test_auc]).reshape(2,-1),\n",
    "                  index = ['train','test'],\n",
    "                  columns = ['Accuracy','Precision','Recall','F1-Score','AUC-Score'])\n",
    "    stack_df_list.append(df)\n",
    "pd.concat(stack_df_list,axis=0,keys=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可以看到，stacking方法还是对提升准确率有一定效果的，但是也可以分析，某些stacking方法做起来之后，效果却不好了，\n",
    "# 要懂原理再去使用stacking，这样才能最好的达到模型的效果\n",
    "# reference:https://zhuanlan.zhihu.com/p/56086368"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
