{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "词频统计\n",
    "---\n",
    "给定一段文本，使用基于字和基于词的词频统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter,defaultdict\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "沙瑞金赞叹易学习的胸怀，是金山的百姓有福，可是这件事对李达康的触动很大。易学习又回忆起他们三人分开的前一晚，大家一起喝酒话别，易学习被降职到道口县当县长，王大路下海经商，李达康连连赔礼道歉，觉得对不起大家，他最对不起的是王大路，就和易学习一起给王大路凑了5万块钱，王大路自己东挪西撮了5万块，开始下海经商。没想到后来王大路竟然做得风生水起。沙瑞金觉得他们三人，在困难时期还能以沫相助，很不容易。\n"
     ]
    }
   ],
   "source": [
    "# 导入语言设计好的词\n",
    "file_path=\"../data\"\n",
    "with open(os.path.join(file_path,'nlp_test0.txt'),'r',encoding='utf-8') as fp:\n",
    "    document=fp.read()\n",
    "    print(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**基于字的评率统计**  \n",
    "主要是设计一个字典，然后进行统计即可\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'沙': 2, '瑞': 2, '金': 3, '赞': 1, '叹': 1, '易': 5, '学': 4, '习': 4, '的': 5, '胸': 1, '怀': 1, '，': 13, '是': 3, '山': 1, '百': 1, '姓': 1, '有': 1, '福': 1, '可': 1, '这': 1, '件': 1, '事': 1, '对': 3, '李': 2, '达': 2, '康': 2, '触': 1, '动': 1, '很': 2, '大': 8, '。': 4, '又': 1, '回': 1, '忆': 1, '起': 6, '他': 3, '们': 2, '三': 2, '人': 2, '分': 1, '开': 2, '前': 1, '一': 3, '晚': 1, '家': 2, '喝': 1, '酒': 1, '话': 1, '别': 1, '被': 1, '降': 1, '职': 1, '到': 2, '道': 2, '口': 1, '县': 2, '当': 1, '长': 1, '王': 5, '路': 5, '下': 2, '海': 2, '经': 2, '商': 2, '连': 2, '赔': 1, '礼': 1, '歉': 1, '觉': 2, '得': 3, '不': 3, '最': 1, '就': 1, '和': 1, '给': 1, '凑': 1, '了': 2, '5': 2, '万': 2, '块': 2, '钱': 1, '自': 1, '己': 1, '东': 1, '挪': 1, '西': 1, '撮': 1, '始': 1, '没': 1, '想': 1, '后': 1, '来': 1, '竟': 1, '然': 1, '做': 1, '风': 1, '生': 1, '水': 1, '在': 1, '困': 1, '难': 1, '时': 1, '期': 1, '还': 1, '能': 1, '以': 1, '沫': 1, '相': 1, '助': 1, '容': 1}\n"
     ]
    }
   ],
   "source": [
    "word_frequency=dict()\n",
    "for word in document:\n",
    "    if word not in word_frequency:\n",
    "        word_frequency[word]=1\n",
    "    else:\n",
    "        word_frequency[word]+=1\n",
    "print(word_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'，': 13, '大': 8, '起': 6, '易': 5, '的': 5, '王': 5, '路': 5, '学': 4, '习': 4, '。': 4, '金': 3, '是': 3, '对': 3, '他': 3, '一': 3, '得': 3, '不': 3, '沙': 2, '瑞': 2, '李': 2, '达': 2, '康': 2, '很': 2, '们': 2, '三': 2, '人': 2, '开': 2, '家': 2, '到': 2, '道': 2, '县': 2, '下': 2, '海': 2, '经': 2, '商': 2, '连': 2, '觉': 2, '了': 2, '5': 2, '万': 2, '块': 2, '赞': 1, '叹': 1, '胸': 1, '怀': 1, '山': 1, '百': 1, '姓': 1, '有': 1, '福': 1, '可': 1, '这': 1, '件': 1, '事': 1, '触': 1, '动': 1, '又': 1, '回': 1, '忆': 1, '分': 1, '前': 1, '晚': 1, '喝': 1, '酒': 1, '话': 1, '别': 1, '被': 1, '降': 1, '职': 1, '口': 1, '当': 1, '长': 1, '赔': 1, '礼': 1, '歉': 1, '最': 1, '就': 1, '和': 1, '给': 1, '凑': 1, '钱': 1, '自': 1, '己': 1, '东': 1, '挪': 1, '西': 1, '撮': 1, '始': 1, '没': 1, '想': 1, '后': 1, '来': 1, '竟': 1, '然': 1, '做': 1, '风': 1, '生': 1, '水': 1, '在': 1, '困': 1, '难': 1, '时': 1, '期': 1, '还': 1, '能': 1, '以': 1, '沫': 1, '相': 1, '助': 1, '容': 1})\n"
     ]
    }
   ],
   "source": [
    "# 或者我们可以直接使用Counter类来帮助我们统计,这种方式是比较快速的，返回的结果都是字典\n",
    "document_counter=Counter(document)\n",
    "print(document_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**基于词的评率统计**  \n",
    "使用基于词的频率统计时，我们要首先进行分词，这里是采用jieba分词工具进行分词，将jieba分词工具之后的结果来进行统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['沙瑞金', '赞叹', '易学习', '的', '胸怀', '，', '是', '金山', '的', '百姓', '有福', '，', '可是', '这件', '事对', '李达康', '的', '触动', '很大', '。', '易学习', '又', '回忆起', '他们', '三人', '分开', '的', '前一晚', '，', '大家', '一起', '喝酒', '话别', '，', '易学习', '被', '降职', '到', '道口', '县当', '县长', '，', '王大路', '下海经商', '，', '李达康', '连连', '赔礼道歉', '，', '觉得', '对不起', '大家', '，', '他', '最', '对不起', '的', '是', '王大路', '，', '就', '和', '易学习', '一起', '给', '王大路', '凑', '了', '5', '万块', '钱', '，', '王大路', '自己', '东挪西撮', '了', '5', '万块', '，', '开始', '下海经商', '。', '没想到', '后来', '王大路', '竟然', '做', '得', '风生水', '起', '。', '沙瑞金', '觉得', '他们', '三人', '，', '在', '困难', '时期', '还', '能', '以沫', '相助', '，', '很', '不', '容易', '。']\n"
     ]
    }
   ],
   "source": [
    "# 为了稍稍保证分词的正确性，我们先稍微该一下我们的分词的词典。\n",
    "jieba.suggest_freq('沙瑞金', True)\n",
    "jieba.suggest_freq('易学习', True)\n",
    "jieba.suggest_freq('王大路', True)\n",
    "jieba.suggest_freq('京州', True)\n",
    "\n",
    "# 返回的是一个迭代器，需要查看结果的话需要将其转换为list\n",
    "document_cut=list(jieba.cut(document))\n",
    "print(document_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'沙瑞金': 2, '赞叹': 1, '易学习': 4, '的': 5, '胸怀': 1, '，': 13, '是': 2, '金山': 1, '百姓': 1, '有福': 1, '可是': 1, '这件': 1, '事对': 1, '李达康': 2, '触动': 1, '很大': 1, '。': 4, '又': 1, '回忆起': 1, '他们': 2, '三人': 2, '分开': 1, '前一晚': 1, '大家': 2, '一起': 2, '喝酒': 1, '话别': 1, '被': 1, '降职': 1, '到': 1, '道口': 1, '县当': 1, '县长': 1, '王大路': 5, '下海经商': 2, '连连': 1, '赔礼道歉': 1, '觉得': 2, '对不起': 2, '他': 1, '最': 1, '就': 1, '和': 1, '给': 1, '凑': 1, '了': 2, '5': 2, '万块': 2, '钱': 1, '自己': 1, '东挪西撮': 1, '开始': 1, '没想到': 1, '后来': 1, '竟然': 1, '做': 1, '得': 1, '风生水': 1, '起': 1, '在': 1, '困难': 1, '时期': 1, '还': 1, '能': 1, '以沫': 1, '相助': 1, '很': 1, '不': 1, '容易': 1}\n"
     ]
    }
   ],
   "source": [
    "# 同样的，按照基于字的频率统计方式，来进行统计词频\n",
    "words_frequency=dict()\n",
    "for word in document_cut:\n",
    "    if word not in words_frequency:\n",
    "        words_frequency[word]=1\n",
    "    else:\n",
    "        words_frequency[word]+=1\n",
    "print(words_frequency)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "文本矩阵化\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'5': 0, '。': 1, '一起': 2, '万块': 3, '三人': 4, '下海经商': 5, '不': 6, '东挪西撮': 7, '了': 8, '事对': 9, '他': 10, '他们': 11, '以沫': 12, '做': 13, '凑': 14, '分开': 15, '到': 16, '前一晚': 17, '县当': 18, '县长': 19, '又': 20, '可是': 21, '后来': 22, '和': 23, '喝酒': 24, '回忆起': 25, '困难': 26, '在': 27, '大家': 28, '容易': 29, '对不起': 30, '就': 31, '开始': 32, '很': 33, '很大': 34, '得': 35, '时期': 36, '易学习': 37, '是': 38, '最': 39, '有福': 40, '李达康': 41, '沙瑞金': 42, '没想到': 43, '王大路': 44, '百姓': 45, '的': 46, '相助': 47, '竟然': 48, '给': 49, '胸怀': 50, '能': 51, '自己': 52, '被': 53, '觉得': 54, '触动': 55, '话别': 56, '赔礼道歉': 57, '赞叹': 58, '起': 59, '还': 60, '这件': 61, '连连': 62, '道口': 63, '金山': 64, '钱': 65, '降职': 66, '风生水': 67, '，': 68}\n",
      "     char  num\n",
      "0     沙瑞金   42\n",
      "1      赞叹   58\n",
      "2     易学习   37\n",
      "3       的   46\n",
      "4      胸怀   50\n",
      "5       ，   68\n",
      "6       是   38\n",
      "7      金山   64\n",
      "8       的   46\n",
      "9      百姓   45\n",
      "10     有福   40\n",
      "11      ，   68\n",
      "12     可是   21\n",
      "13     这件   61\n",
      "14     事对    9\n",
      "15    李达康   41\n",
      "16      的   46\n",
      "17     触动   55\n",
      "18     很大   34\n",
      "19      。    1\n",
      "20    易学习   37\n",
      "21      又   20\n",
      "22    回忆起   25\n",
      "23     他们   11\n",
      "24     三人    4\n",
      "25     分开   15\n",
      "26      的   46\n",
      "27    前一晚   17\n",
      "28      ，   68\n",
      "29     大家   28\n",
      "..    ...  ...\n",
      "78      ，   68\n",
      "79     开始   32\n",
      "80   下海经商    5\n",
      "81      。    1\n",
      "82    没想到   43\n",
      "83     后来   22\n",
      "84    王大路   44\n",
      "85     竟然   48\n",
      "86      做   13\n",
      "87      得   35\n",
      "88    风生水   67\n",
      "89      起   59\n",
      "90      。    1\n",
      "91    沙瑞金   42\n",
      "92     觉得   54\n",
      "93     他们   11\n",
      "94     三人    4\n",
      "95      ，   68\n",
      "96      在   27\n",
      "97     困难   26\n",
      "98     时期   36\n",
      "99      还   60\n",
      "100     能   51\n",
      "101    以沫   12\n",
      "102    相助   47\n",
      "103     ，   68\n",
      "104     很   33\n",
      "105     不    6\n",
      "106    容易   29\n",
      "107     。    1\n",
      "\n",
      "[108 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# first ： 分词以及去除停用词\n",
    "with open(os.path.join(file_path,'nlp_test0.txt'),'r',encoding='utf-8') as fp:\n",
    "    document=fp.read()\n",
    "    a_list = [each for each in jieba.cut(document)]\n",
    "\n",
    "# second : 生成词语与数字对应的字典,加sorted仅仅是为了结果好看，使用zip()函数将这两个内容建立起联系\n",
    "char2num = dict(zip(sorted(list(set(a_list))),range(0,len(set(a_list)))))\n",
    "print(char2num)\n",
    "\n",
    "# third : 词语换成数字.此处使用DataFrame的一个特点进行置换\n",
    "aa = pd.DataFrame()\n",
    "aa['char'] = a_list\n",
    "aa['num'] = aa['char'].map(char2num)\n",
    "print(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
